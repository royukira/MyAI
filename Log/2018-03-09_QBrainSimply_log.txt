Update to ---O--T
--> Episode: 0                                    
--> Step: 1                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 0                                    
--> Step: 2                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -----OT
--> Episode: 0                                    
--> Step: 3                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 0                                    
--> Step: 4                                     
--> Next State: 4                                     
--> Chosen Action by current state: left                                     
--> New Q[5,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 0                                    
--> Step: 5                                     
--> Next State: 3                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 6                                     
--> Next State: 2                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 7                                     
--> Next State: 1                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 8                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 0                                    
--> Step: 9                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 10                                     
--> Next State: 2                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 0                                    
--> Step: 11                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 0                                    
--> Step: 12                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -----OT
--> Episode: 0                                    
--> Step: 13                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to Terminal
--> Episode: 0                                                        
--> Step: 14                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.1000000                                                        
--> Target-Predict: 1.0000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.0000000                                                         
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 3                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 1                                    
--> Step: 4                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -----OT
--> Episode: 1                                    
--> Step: 5                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0090000                                    
--> MAX Q[S_next,A] = 0.1000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0900000                                     
--> Q_target: 0.0900000                                     
--> Q_predict: 0.0000000                                     
===========
Update to Terminal
--> Episode: 1                                                        
--> Step: 6                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.1900000                                                        
--> Target-Predict: 0.9000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.1000000                                                         
===========
Update to -O----T
--> Episode: 2                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 2                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 2                                    
--> Step: 3                                     
--> Next State: 1                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 2                                    
--> Step: 4                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 2                                    
--> Step: 5                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 2                                    
--> Step: 6                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 2                                    
--> Step: 7                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 2                                    
--> Step: 8                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 2                                    
--> Step: 9                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 2                                    
--> Step: 10                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 2                                    
--> Step: 11                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 2                                    
--> Step: 12                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 2                                    
--> Step: 13                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 2                                    
--> Step: 14                                     
--> Next State: 1                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 2                                    
--> Step: 15                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 2                                    
--> Step: 16                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 2                                    
--> Step: 17                                     
--> Next State: 2                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 2                                    
--> Step: 18                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 2                                    
--> Step: 19                                     
--> Next State: 2                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 2                                    
--> Step: 20                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 2                                    
--> Step: 21                                     
--> Next State: 2                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 2                                    
--> Step: 22                                     
--> Next State: 1                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 2                                    
--> Step: 23                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 2                                    
--> Step: 24                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 2                                    
--> Step: 25                                     
--> Next State: 2                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 2                                    
--> Step: 26                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 2                                    
--> Step: 27                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0008100                                    
--> MAX Q[S_next,A] = 0.0090000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0081000                                     
--> Q_target: 0.0081000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -----OT
--> Episode: 2                                    
--> Step: 28                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0252000                                    
--> MAX Q[S_next,A] = 0.1900000                                    
--> Reward: 0                                     
--> Target-Predict: 0.1620000                                     
--> Q_target: 0.1710000                                     
--> Q_predict: 0.0090000                                     
===========
Update to ----O-T
--> Episode: 2                                    
--> Step: 29                                     
--> Next State: 4                                     
--> Chosen Action by current state: left                                     
--> New Q[5,left] = 0.0022680                                    
--> MAX Q[S_next,A] = 0.0252000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0226800                                     
--> Q_target: 0.0226800                                     
--> Q_predict: 0.0000000                                     
===========
Update to -----OT
--> Episode: 2                                    
--> Step: 30                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0397800                                    
--> MAX Q[S_next,A] = 0.1900000                                    
--> Reward: 0                                     
--> Target-Predict: 0.1458000                                     
--> Q_target: 0.1710000                                     
--> Q_predict: 0.0252000                                     
===========
Update to Terminal
--> Episode: 2                                                        
--> Step: 31                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.2710000                                                        
--> Target-Predict: 0.8100000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.1900000                                                         
===========
Update to ----O-T
--> Episode: 3                                    
--> Step: 1                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0043092                                    
--> MAX Q[S_next,A] = 0.0397800                                    
--> Reward: 0                                     
--> Target-Predict: 0.0349920                                     
--> Q_target: 0.0358020                                     
--> Q_predict: 0.0008100                                     
===========
Update to -----OT
--> Episode: 3                                    
--> Step: 2                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0601920                                    
--> MAX Q[S_next,A] = 0.2710000                                    
--> Reward: 0                                     
--> Target-Predict: 0.2041200                                     
--> Q_target: 0.2439000                                     
--> Q_predict: 0.0397800                                     
===========
Update to Terminal
--> Episode: 3                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.3439000                                                        
--> Target-Predict: 0.7290000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.2710000                                                         
===========
Update to O-----T
--> Episode: 4                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 4                                    
--> Step: 2                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 4                                    
--> Step: 3                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 4                                    
--> Step: 4                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0003878                                    
--> MAX Q[S_next,A] = 0.0043092                                    
--> Reward: 0                                     
--> Target-Predict: 0.0038783                                     
--> Q_target: 0.0038783                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 4                                    
--> Step: 5                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0092956                                    
--> MAX Q[S_next,A] = 0.0601920                                    
--> Reward: 0                                     
--> Target-Predict: 0.0498636                                     
--> Q_target: 0.0541728                                     
--> Q_predict: 0.0043092                                     
===========
Update to -----OT
--> Episode: 4                                    
--> Step: 6                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0851238                                    
--> MAX Q[S_next,A] = 0.3439000                                    
--> Reward: 0                                     
--> Target-Predict: 0.2493180                                     
--> Q_target: 0.3095100                                     
--> Q_predict: 0.0601920                                     
===========
Update to Terminal
--> Episode: 4                                                        
--> Step: 7                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.4095100                                                        
--> Target-Predict: 0.6561000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.3439000                                                         
===========
Update to -O----T
--> Episode: 5                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 5                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000349                                    
--> MAX Q[S_next,A] = 0.0003878                                    
--> Reward: 0                                     
--> Target-Predict: 0.0003490                                     
--> Q_target: 0.0003490                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 5                                    
--> Step: 3                                     
--> Next State: 1                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000031                                    
--> MAX Q[S_next,A] = 0.0000349                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000314                                     
--> Q_target: 0.0000314                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 5                                    
--> Step: 4                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 5                                    
--> Step: 5                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 5                                    
--> Step: 6                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 5                                    
--> Step: 7                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 5                                    
--> Step: 8                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000031                                    
--> MAX Q[S_next,A] = 0.0000349                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000314                                     
--> Q_target: 0.0000314                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 5                                    
--> Step: 9                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000003                                    
--> MAX Q[S_next,A] = 0.0000031                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000028                                     
--> Q_target: 0.0000028                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 5                                    
--> Step: 10                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000060                                    
--> MAX Q[S_next,A] = 0.0000349                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000283                                     
--> Q_target: 0.0000314                                     
--> Q_predict: 0.0000031                                     
===========
Update to --O---T
--> Episode: 5                                    
--> Step: 11                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000663                                    
--> MAX Q[S_next,A] = 0.0003878                                    
--> Reward: 0                                     
--> Target-Predict: 0.0003141                                     
--> Q_target: 0.0003490                                     
--> Q_predict: 0.0000349                                     
===========
Update to ---O--T
--> Episode: 5                                    
--> Step: 12                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0011856                                    
--> MAX Q[S_next,A] = 0.0092956                                    
--> Reward: 0                                     
--> Target-Predict: 0.0079782                                     
--> Q_target: 0.0083660                                     
--> Q_predict: 0.0003878                                     
===========
Update to --O---T
--> Episode: 5                                    
--> Step: 13                                     
--> Next State: 2                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0001067                                    
--> MAX Q[S_next,A] = 0.0011856                                    
--> Reward: 0                                     
--> Target-Predict: 0.0010671                                     
--> Q_target: 0.0010671                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 5                                    
--> Step: 14                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0019037                                    
--> MAX Q[S_next,A] = 0.0092956                                    
--> Reward: 0                                     
--> Target-Predict: 0.0071804                                     
--> Q_target: 0.0083660                                     
--> Q_predict: 0.0011856                                     
===========
Update to --O---T
--> Episode: 5                                    
--> Step: 15                                     
--> Next State: 2                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0002674                                    
--> MAX Q[S_next,A] = 0.0019037                                    
--> Reward: 0                                     
--> Target-Predict: 0.0016066                                     
--> Q_target: 0.0017133                                     
--> Q_predict: 0.0001067                                     
===========
Update to ---O--T
--> Episode: 5                                    
--> Step: 16                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0025499                                    
--> MAX Q[S_next,A] = 0.0092956                                    
--> Reward: 0                                     
--> Target-Predict: 0.0064623                                     
--> Q_target: 0.0083660                                     
--> Q_predict: 0.0019037                                     
===========
Update to ----O-T
--> Episode: 5                                    
--> Step: 17                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0160271                                    
--> MAX Q[S_next,A] = 0.0851238                                    
--> Reward: 0                                     
--> Target-Predict: 0.0673159                                     
--> Q_target: 0.0766114                                     
--> Q_predict: 0.0092956                                     
===========
Update to ---O--T
--> Episode: 5                                    
--> Step: 18                                     
--> Next State: 3                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0014424                                    
--> MAX Q[S_next,A] = 0.0160271                                    
--> Reward: 0                                     
--> Target-Predict: 0.0144244                                     
--> Q_target: 0.0144244                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 5                                    
--> Step: 19                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0220856                                    
--> MAX Q[S_next,A] = 0.0851238                                    
--> Reward: 0                                     
--> Target-Predict: 0.0605843                                     
--> Q_target: 0.0766114                                     
--> Q_predict: 0.0160271                                     
===========
Update to -----OT
--> Episode: 5                                    
--> Step: 20                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.1134673                                    
--> MAX Q[S_next,A] = 0.4095100                                    
--> Reward: 0                                     
--> Target-Predict: 0.2834352                                     
--> Q_target: 0.3685590                                     
--> Q_predict: 0.0851238                                     
===========
Update to Terminal
--> Episode: 5                                                        
--> Step: 21                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.4685590                                                        
--> Target-Predict: 0.5904900                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.4095100                                                         
===========
Update to ---O--T
--> Episode: 6                                    
--> Step: 1                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0042826                                    
--> MAX Q[S_next,A] = 0.0220856                                    
--> Reward: 0                                     
--> Target-Predict: 0.0173271                                     
--> Q_target: 0.0198770                                     
--> Q_predict: 0.0025499                                     
===========
Update to ----O-T
--> Episode: 6                                    
--> Step: 2                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0300891                                    
--> MAX Q[S_next,A] = 0.1134673                                    
--> Reward: 0                                     
--> Target-Predict: 0.0800350                                     
--> Q_target: 0.1021206                                     
--> Q_predict: 0.0220856                                     
===========
Update to -----OT
--> Episode: 6                                    
--> Step: 3                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.1442909                                    
--> MAX Q[S_next,A] = 0.4685590                                    
--> Reward: 0                                     
--> Target-Predict: 0.3082358                                     
--> Q_target: 0.4217031                                     
--> Q_predict: 0.1134673                                     
===========
Update to Terminal
--> Episode: 6                                                        
--> Step: 4                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.5217031                                                        
--> Target-Predict: 0.5314410                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.4685590                                                         
===========
Update to ---O--T
--> Episode: 7                                    
--> Step: 1                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0065624                                    
--> MAX Q[S_next,A] = 0.0300891                                    
--> Reward: 0                                     
--> Target-Predict: 0.0227975                                     
--> Q_target: 0.0270802                                     
--> Q_predict: 0.0042826                                     
===========
Update to ----O-T
--> Episode: 7                                    
--> Step: 2                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0400663                                    
--> MAX Q[S_next,A] = 0.1442909                                    
--> Reward: 0                                     
--> Target-Predict: 0.0997727                                     
--> Q_target: 0.1298618                                     
--> Q_predict: 0.0300891                                     
===========
Update to -----OT
--> Episode: 7                                    
--> Step: 3                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.1768151                                    
--> MAX Q[S_next,A] = 0.5217031                                    
--> Reward: 0                                     
--> Target-Predict: 0.3252419                                     
--> Q_target: 0.4695328                                     
--> Q_predict: 0.1442909                                     
===========
Update to Terminal
--> Episode: 7                                                        
--> Step: 4                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.5695328                                                        
--> Target-Predict: 0.4782969                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.5217031                                                         
===========
Update to --O---T
--> Episode: 8                                    
--> Step: 1                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0006503                                    
--> MAX Q[S_next,A] = 0.0065624                                    
--> Reward: 0                                     
--> Target-Predict: 0.0058398                                     
--> Q_target: 0.0059061                                     
--> Q_predict: 0.0000663                                     
===========
Update to ---O--T
--> Episode: 8                                    
--> Step: 2                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0095121                                    
--> MAX Q[S_next,A] = 0.0400663                                    
--> Reward: 0                                     
--> Target-Predict: 0.0294973                                     
--> Q_target: 0.0360597                                     
--> Q_predict: 0.0065624                                     
===========
Update to ----O-T
--> Episode: 8                                    
--> Step: 3                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0519731                                    
--> MAX Q[S_next,A] = 0.1768151                                    
--> Reward: 0                                     
--> Target-Predict: 0.1190672                                     
--> Q_target: 0.1591336                                     
--> Q_predict: 0.0400663                                     
===========
Update to -----OT
--> Episode: 8                                    
--> Step: 4                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.2103915                                    
--> MAX Q[S_next,A] = 0.5695328                                    
--> Reward: 0                                     
--> Target-Predict: 0.3357644                                     
--> Q_target: 0.5125795                                     
--> Q_predict: 0.1768151                                     
===========
Update to ----O-T
--> Episode: 8                                    
--> Step: 5                                     
--> Next State: 4                                     
--> Chosen Action by current state: left                                     
--> New Q[5,left] = 0.0209764                                    
--> MAX Q[S_next,A] = 0.2103915                                    
--> Reward: 0                                     
--> Target-Predict: 0.1870844                                     
--> Q_target: 0.1893524                                     
--> Q_predict: 0.0022680                                     
===========
Update to -----OT
--> Episode: 8                                    
--> Step: 6                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.2406103                                    
--> MAX Q[S_next,A] = 0.5695328                                    
--> Reward: 0                                     
--> Target-Predict: 0.3021880                                     
--> Q_target: 0.5125795                                     
--> Q_predict: 0.2103915                                     
===========
Update to ----O-T
--> Episode: 8                                    
--> Step: 7                                     
--> Next State: 4                                     
--> Chosen Action by current state: left                                     
--> New Q[5,left] = 0.0405337                                    
--> MAX Q[S_next,A] = 0.2406103                                    
--> Reward: 0                                     
--> Target-Predict: 0.1955729                                     
--> Q_target: 0.2165493                                     
--> Q_predict: 0.0209764                                     
===========
Update to -----OT
--> Episode: 8                                    
--> Step: 8                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.2678072                                    
--> MAX Q[S_next,A] = 0.5695328                                    
--> Reward: 0                                     
--> Target-Predict: 0.2719692                                     
--> Q_target: 0.5125795                                     
--> Q_predict: 0.2406103                                     
===========
Update to Terminal
--> Episode: 8                                                        
--> Step: 9                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.6125795                                                        
--> Target-Predict: 0.4304672                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.5695328                                                         
===========
Update to -O----T
--> Episode: 9                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000639                                    
--> MAX Q[S_next,A] = 0.0006503                                    
--> Reward: 0                                     
--> Target-Predict: 0.0005793                                     
--> Q_target: 0.0005853                                     
--> Q_predict: 0.0000060                                     
===========
Update to --O---T
--> Episode: 9                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0014414                                    
--> MAX Q[S_next,A] = 0.0095121                                    
--> Reward: 0                                     
--> Target-Predict: 0.0079106                                     
--> Q_target: 0.0085609                                     
--> Q_predict: 0.0006503                                     
===========
Update to ---O--T
--> Episode: 9                                    
--> Step: 3                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0132385                                    
--> MAX Q[S_next,A] = 0.0519731                                    
--> Reward: 0                                     
--> Target-Predict: 0.0372637                                     
--> Q_target: 0.0467758                                     
--> Q_predict: 0.0095121                                     
===========
Update to ----O-T
--> Episode: 9                                    
--> Step: 4                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0708784                                    
--> MAX Q[S_next,A] = 0.2678072                                    
--> Reward: 0                                     
--> Target-Predict: 0.1890535                                     
--> Q_target: 0.2410265                                     
--> Q_predict: 0.0519731                                     
===========
Update to -----OT
--> Episode: 9                                    
--> Step: 5                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.2961587                                    
--> MAX Q[S_next,A] = 0.6125795                                    
--> Reward: 0                                     
--> Target-Predict: 0.2835143                                     
--> Q_target: 0.5513216                                     
--> Q_predict: 0.2678072                                     
===========
Update to Terminal
--> Episode: 9                                                        
--> Step: 6                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.6513216                                                        
--> Target-Predict: 0.3874205                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6125795                                                         
===========
Update to ----O-T
--> Episode: 10                                    
--> Step: 1                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0904449                                    
--> MAX Q[S_next,A] = 0.2961587                                    
--> Reward: 0                                     
--> Target-Predict: 0.1956644                                     
--> Q_target: 0.2665428                                     
--> Q_predict: 0.0708784                                     
===========
Update to ---O--T
--> Episode: 10                                    
--> Step: 2                                     
--> Next State: 3                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0094382                                    
--> MAX Q[S_next,A] = 0.0904449                                    
--> Reward: 0                                     
--> Target-Predict: 0.0799579                                     
--> Q_target: 0.0814004                                     
--> Q_predict: 0.0014424                                     
===========
Update to ----O-T
--> Episode: 10                                    
--> Step: 3                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.1080547                                    
--> MAX Q[S_next,A] = 0.2961587                                    
--> Reward: 0                                     
--> Target-Predict: 0.1760980                                     
--> Q_target: 0.2665428                                     
--> Q_predict: 0.0904449                                     
===========
Update to -----OT
--> Episode: 10                                    
--> Step: 4                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.3251618                                    
--> MAX Q[S_next,A] = 0.6513216                                    
--> Reward: 0                                     
--> Target-Predict: 0.2900307                                     
--> Q_target: 0.5861894                                     
--> Q_predict: 0.2961587                                     
===========
Update to Terminal
--> Episode: 10                                                        
--> Step: 5                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.6861894                                                        
--> Target-Predict: 0.3486784                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6513216                                                         
===========
Update to --O---T
--> Episode: 11                                    
--> Step: 1                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0024887                                    
--> MAX Q[S_next,A] = 0.0132385                                    
--> Reward: 0                                     
--> Target-Predict: 0.0104733                                     
--> Q_target: 0.0119146                                     
--> Q_predict: 0.0014414                                     
===========
Update to ---O--T
--> Episode: 11                                    
--> Step: 2                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0216395                                    
--> MAX Q[S_next,A] = 0.1080547                                    
--> Reward: 0                                     
--> Target-Predict: 0.0840107                                     
--> Q_target: 0.0972492                                     
--> Q_predict: 0.0132385                                     
===========
Update to ----O-T
--> Episode: 11                                    
--> Step: 3                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.1265137                                    
--> MAX Q[S_next,A] = 0.3251618                                    
--> Reward: 0                                     
--> Target-Predict: 0.1845909                                     
--> Q_target: 0.2926456                                     
--> Q_predict: 0.1080547                                     
===========
Update to -----OT
--> Episode: 11                                    
--> Step: 4                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.3544026                                    
--> MAX Q[S_next,A] = 0.6861894                                    
--> Reward: 0                                     
--> Target-Predict: 0.2924087                                     
--> Q_target: 0.6175705                                     
--> Q_predict: 0.3251618                                     
===========
Update to Terminal
--> Episode: 11                                                        
--> Step: 5                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.7175705                                                        
--> Target-Predict: 0.3138106                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6861894                                                         
===========
Update to ---O--T
--> Episode: 12                                    
--> Step: 1                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0308618                                    
--> MAX Q[S_next,A] = 0.1265137                                    
--> Reward: 0                                     
--> Target-Predict: 0.0922228                                     
--> Q_target: 0.1138624                                     
--> Q_predict: 0.0216395                                     
===========
Update to ----O-T
--> Episode: 12                                    
--> Step: 2                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.1457586                                    
--> MAX Q[S_next,A] = 0.3544026                                    
--> Reward: 0                                     
--> Target-Predict: 0.1924486                                     
--> Q_target: 0.3189624                                     
--> Q_predict: 0.1265137                                     
===========
Update to -----OT
--> Episode: 12                                    
--> Step: 3                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.3835437                                    
--> MAX Q[S_next,A] = 0.7175705                                    
--> Reward: 0                                     
--> Target-Predict: 0.2914108                                     
--> Q_target: 0.6458134                                     
--> Q_predict: 0.3544026                                     
===========
Update to Terminal
--> Episode: 12                                                        
--> Step: 4                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.7458134                                                        
--> Target-Predict: 0.2824295                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.7175705                                                         
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 2                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 4                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 5                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 6                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 0                                    
--> Step: 7                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 0                                    
--> Step: 8                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 9                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 10                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 11                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 12                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 13                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 14                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 15                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 16                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 17                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 18                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 19                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 20                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 21                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 22                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 23                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 24                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 25                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 26                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 27                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 28                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 29                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 30                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 0                                    
--> Step: 31                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 32                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 33                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 34                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 35                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 36                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 37                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 38                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 39                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 40                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 41                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 0                                    
--> Step: 42                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 0                                    
--> Step: 43                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 44                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 45                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 46                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 47                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 48                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 49                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 50                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 51                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 52                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 53                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 54                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 55                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 56                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 57                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 58                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 59                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 60                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 61                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 62                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 63                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 64                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 65                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 66                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 67                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 68                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 69                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 70                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 71                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 72                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 73                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 74                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 0                                    
--> Step: 75                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 0                                    
--> Step: 76                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 77                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 78                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 79                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 80                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 81                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 82                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 83                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 84                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 85                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 86                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 87                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 88                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 89                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 90                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 91                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 92                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 93                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 94                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 95                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 96                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 97                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 98                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 99                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 100                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 101                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 102                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 0                                    
--> Step: 103                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 0                                    
--> Step: 104                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 0                                    
--> Step: 105                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 0                                    
--> Step: 106                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 0                                    
--> Step: 107                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -----OT
--> Episode: 0                                    
--> Step: 108                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to Terminal
--> Episode: 0                                                        
--> Step: 109                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.1000000                                                        
--> Target-Predict: 1.0000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.0000000                                                         
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 2                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 4                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 5                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 6                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 7                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 8                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 9                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 10                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 11                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 12                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 13                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 14                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 15                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 16                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 17                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 18                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 19                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 20                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 21                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 22                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 23                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 24                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 25                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 26                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 27                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 1                                    
--> Step: 28                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 29                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 30                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 31                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 32                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 33                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 34                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 35                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 36                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 37                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 38                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 1                                    
--> Step: 39                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -----OT
--> Episode: 1                                    
--> Step: 40                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0090000                                    
--> MAX Q[S_next,A] = 0.1000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0900000                                     
--> Q_target: 0.0900000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 41                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[5,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 42                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 43                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 44                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 45                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 46                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 47                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 48                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 49                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 50                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 51                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 52                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 53                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 54                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 55                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 56                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 57                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 58                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 59                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 60                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ----O-T
--> Episode: 1                                    
--> Step: 61                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0008100                                    
--> MAX Q[S_next,A] = 0.0090000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0081000                                     
--> Q_target: 0.0081000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 62                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 63                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 64                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 65                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 66                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 67                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 68                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 69                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 70                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 71                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 72                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 73                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 74                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 75                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 76                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 77                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 78                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 79                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 80                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 81                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 82                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 83                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0000729                                    
--> MAX Q[S_next,A] = 0.0008100                                    
--> Reward: 0                                     
--> Target-Predict: 0.0007290                                     
--> Q_target: 0.0007290                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 84                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 85                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 86                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 87                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 88                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000066                                    
--> MAX Q[S_next,A] = 0.0000729                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000656                                     
--> Q_target: 0.0000656                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 89                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 90                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 91                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 92                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000006                                    
--> MAX Q[S_next,A] = 0.0000066                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000059                                     
--> Q_target: 0.0000059                                     
--> Q_predict: 0.0000000                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 93                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000125                                    
--> MAX Q[S_next,A] = 0.0000729                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000590                                     
--> Q_target: 0.0000656                                     
--> Q_predict: 0.0000066                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 94                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000001                                    
--> MAX Q[S_next,A] = 0.0000006                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000005                                     
--> Q_target: 0.0000005                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 95                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000017                                    
--> MAX Q[S_next,A] = 0.0000125                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000106                                     
--> Q_target: 0.0000112                                     
--> Q_predict: 0.0000006                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 96                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000178                                    
--> MAX Q[S_next,A] = 0.0000729                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000531                                     
--> Q_target: 0.0000656                                     
--> Q_predict: 0.0000125                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 97                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0001385                                    
--> MAX Q[S_next,A] = 0.0008100                                    
--> Reward: 0                                     
--> Target-Predict: 0.0006561                                     
--> Q_target: 0.0007290                                     
--> Q_predict: 0.0000729                                     
===========
Update to ----O-T
--> Episode: 1                                    
--> Step: 98                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0015390                                    
--> MAX Q[S_next,A] = 0.0090000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0072900                                     
--> Q_target: 0.0081000                                     
--> Q_predict: 0.0008100                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 99                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0000001                                    
--> MAX Q[S_next,A] = 0.0000017                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000015                                     
--> Q_target: 0.0000015                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 100                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000001                                    
--> MAX Q[S_next,A] = 0.0000017                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000015                                     
--> Q_target: 0.0000015                                     
--> Q_predict: 0.0000000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 101                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000003                                    
--> MAX Q[S_next,A] = 0.0000017                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000013                                     
--> Q_target: 0.0000015                                     
--> Q_predict: 0.0000001                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 102                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000031                                    
--> MAX Q[S_next,A] = 0.0000178                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000143                                     
--> Q_target: 0.0000160                                     
--> Q_predict: 0.0000017                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 103                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000003                                    
--> MAX Q[S_next,A] = 0.0000031                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000028                                     
--> Q_target: 0.0000028                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 104                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000044                                    
--> MAX Q[S_next,A] = 0.0000178                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000129                                     
--> Q_target: 0.0000160                                     
--> Q_predict: 0.0000031                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 105                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000285                                    
--> MAX Q[S_next,A] = 0.0001385                                    
--> Reward: 0                                     
--> Target-Predict: 0.0001069                                     
--> Q_target: 0.0001247                                     
--> Q_predict: 0.0000178                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 106                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0002632                                    
--> MAX Q[S_next,A] = 0.0015390                                    
--> Reward: 0                                     
--> Target-Predict: 0.0012466                                     
--> Q_target: 0.0013851                                     
--> Q_predict: 0.0001385                                     
===========
Update to ----O-T
--> Episode: 1                                    
--> Step: 107                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0021951                                    
--> MAX Q[S_next,A] = 0.0090000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0065610                                     
--> Q_target: 0.0081000                                     
--> Q_predict: 0.0015390                                     
===========
Update to -----OT
--> Episode: 1                                    
--> Step: 108                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0171000                                    
--> MAX Q[S_next,A] = 0.1000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0810000                                     
--> Q_target: 0.0900000                                     
--> Q_predict: 0.0090000                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 109                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[5,left] = 0.0000004                                    
--> MAX Q[S_next,A] = 0.0000044                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000039                                     
--> Q_target: 0.0000039                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 110                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000065                                    
--> MAX Q[S_next,A] = 0.0000285                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000212                                     
--> Q_target: 0.0000256                                     
--> Q_predict: 0.0000044                                     
===========
Update to O-----T
--> Episode: 1                                    
--> Step: 111                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000008                                    
--> MAX Q[S_next,A] = 0.0000065                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000056                                     
--> Q_target: 0.0000059                                     
--> Q_predict: 0.0000003                                     
===========
Update to -O----T
--> Episode: 1                                    
--> Step: 112                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000084                                    
--> MAX Q[S_next,A] = 0.0000285                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000191                                     
--> Q_target: 0.0000256                                     
--> Q_predict: 0.0000065                                     
===========
Update to --O---T
--> Episode: 1                                    
--> Step: 113                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000493                                    
--> MAX Q[S_next,A] = 0.0002632                                    
--> Reward: 0                                     
--> Target-Predict: 0.0002084                                     
--> Q_target: 0.0002369                                     
--> Q_predict: 0.0000285                                     
===========
Update to ---O--T
--> Episode: 1                                    
--> Step: 114                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0004344                                    
--> MAX Q[S_next,A] = 0.0021951                                    
--> Reward: 0                                     
--> Target-Predict: 0.0017124                                     
--> Q_target: 0.0019756                                     
--> Q_predict: 0.0002632                                     
===========
Update to ----O-T
--> Episode: 1                                    
--> Step: 115                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0035146                                    
--> MAX Q[S_next,A] = 0.0171000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0131949                                     
--> Q_target: 0.0153900                                     
--> Q_predict: 0.0021951                                     
===========
Update to -----OT
--> Episode: 1                                    
--> Step: 116                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0243900                                    
--> MAX Q[S_next,A] = 0.1000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0729000                                     
--> Q_target: 0.0900000                                     
--> Q_predict: 0.0171000                                     
===========
Update to Terminal
--> Episode: 1                                                        
--> Step: 117                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.1900000                                                        
--> Target-Predict: 0.9000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.1000000                                                         
===========
Update to --O---T
--> Episode: 2                                    
--> Step: 1                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000835                                    
--> MAX Q[S_next,A] = 0.0004344                                    
--> Reward: 0                                     
--> Target-Predict: 0.0003417                                     
--> Q_target: 0.0003910                                     
--> Q_predict: 0.0000493                                     
===========
Update to ---O--T
--> Episode: 2                                    
--> Step: 2                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0007073                                    
--> MAX Q[S_next,A] = 0.0035146                                    
--> Reward: 0                                     
--> Target-Predict: 0.0027287                                     
--> Q_target: 0.0031631                                     
--> Q_predict: 0.0004344                                     
===========
Update to ----O-T
--> Episode: 2                                    
--> Step: 3                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0053582                                    
--> MAX Q[S_next,A] = 0.0243900                                    
--> Reward: 0                                     
--> Target-Predict: 0.0184364                                     
--> Q_target: 0.0219510                                     
--> Q_predict: 0.0035146                                     
===========
Update to -----OT
--> Episode: 2                                    
--> Step: 4                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0390510                                    
--> MAX Q[S_next,A] = 0.1900000                                    
--> Reward: 0                                     
--> Target-Predict: 0.1466100                                     
--> Q_target: 0.1710000                                     
--> Q_predict: 0.0243900                                     
===========
Update to Terminal
--> Episode: 2                                                        
--> Step: 5                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.2710000                                                        
--> Target-Predict: 0.8100000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.1900000                                                         
===========
Update to ----O-T
--> Episode: 3                                    
--> Step: 1                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0083370                                    
--> MAX Q[S_next,A] = 0.0390510                                    
--> Reward: 0                                     
--> Target-Predict: 0.0297877                                     
--> Q_target: 0.0351459                                     
--> Q_predict: 0.0053582                                     
===========
Update to -----OT
--> Episode: 3                                    
--> Step: 2                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0595359                                    
--> MAX Q[S_next,A] = 0.2710000                                    
--> Reward: 0                                     
--> Target-Predict: 0.2048490                                     
--> Q_target: 0.2439000                                     
--> Q_predict: 0.0390510                                     
===========
Update to Terminal
--> Episode: 3                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.3439000                                                        
--> Target-Predict: 0.7290000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.2710000                                                         
===========
Update to -O----T
--> Episode: 4                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000151                                    
--> MAX Q[S_next,A] = 0.0000835                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000667                                     
--> Q_target: 0.0000751                                     
--> Q_predict: 0.0000084                                     
===========
Update to --O---T
--> Episode: 4                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0001388                                    
--> MAX Q[S_next,A] = 0.0007073                                    
--> Reward: 0                                     
--> Target-Predict: 0.0005531                                     
--> Q_target: 0.0006366                                     
--> Q_predict: 0.0000835                                     
===========
Update to ---O--T
--> Episode: 4                                    
--> Step: 3                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0013869                                    
--> MAX Q[S_next,A] = 0.0083370                                    
--> Reward: 0                                     
--> Target-Predict: 0.0067960                                     
--> Q_target: 0.0075033                                     
--> Q_predict: 0.0007073                                     
===========
Update to ----O-T
--> Episode: 4                                    
--> Step: 4                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0128615                                    
--> MAX Q[S_next,A] = 0.0595359                                    
--> Reward: 0                                     
--> Target-Predict: 0.0452453                                     
--> Q_target: 0.0535823                                     
--> Q_predict: 0.0083370                                     
===========
Update to -----OT
--> Episode: 4                                    
--> Step: 5                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.0845333                                    
--> MAX Q[S_next,A] = 0.3439000                                    
--> Reward: 0                                     
--> Target-Predict: 0.2499741                                     
--> Q_target: 0.3095100                                     
--> Q_predict: 0.0595359                                     
===========
Update to Terminal
--> Episode: 4                                                        
--> Step: 6                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.4095100                                                        
--> Target-Predict: 0.6561000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.3439000                                                         
===========
Update to -O----T
--> Episode: 5                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000261                                    
--> MAX Q[S_next,A] = 0.0001388                                    
--> Reward: 0                                     
--> Target-Predict: 0.0001098                                     
--> Q_target: 0.0001249                                     
--> Q_predict: 0.0000151                                     
===========
Update to --O---T
--> Episode: 5                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0002497                                    
--> MAX Q[S_next,A] = 0.0013869                                    
--> Reward: 0                                     
--> Target-Predict: 0.0011094                                     
--> Q_target: 0.0012482                                     
--> Q_predict: 0.0001388                                     
===========
Update to ---O--T
--> Episode: 5                                    
--> Step: 3                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0024057                                    
--> MAX Q[S_next,A] = 0.0128615                                    
--> Reward: 0                                     
--> Target-Predict: 0.0101885                                     
--> Q_target: 0.0115754                                     
--> Q_predict: 0.0013869                                     
===========
Update to O-----T
--> Episode: 5                                    
--> Step: 4                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000023                                    
--> MAX Q[S_next,A] = 0.0000261                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000235                                     
--> Q_target: 0.0000235                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O----T
--> Episode: 5                                    
--> Step: 5                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000459                                    
--> MAX Q[S_next,A] = 0.0002497                                    
--> Reward: 0                                     
--> Target-Predict: 0.0001987                                     
--> Q_target: 0.0002248                                     
--> Q_predict: 0.0000261                                     
===========
Update to --O---T
--> Episode: 5                                    
--> Step: 6                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0004413                                    
--> MAX Q[S_next,A] = 0.0024057                                    
--> Reward: 0                                     
--> Target-Predict: 0.0019154                                     
--> Q_target: 0.0021652                                     
--> Q_predict: 0.0002497                                     
===========
Update to ---O--T
--> Episode: 5                                    
--> Step: 7                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0033227                                    
--> MAX Q[S_next,A] = 0.0128615                                    
--> Reward: 0                                     
--> Target-Predict: 0.0091696                                     
--> Q_target: 0.0115754                                     
--> Q_predict: 0.0024057                                     
===========
Update to ----O-T
--> Episode: 5                                    
--> Step: 8                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0191834                                    
--> MAX Q[S_next,A] = 0.0845333                                    
--> Reward: 0                                     
--> Target-Predict: 0.0632184                                     
--> Q_target: 0.0760800                                     
--> Q_predict: 0.0128615                                     
===========
Update to -----OT
--> Episode: 5                                    
--> Step: 9                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.1129359                                    
--> MAX Q[S_next,A] = 0.4095100                                    
--> Reward: 0                                     
--> Target-Predict: 0.2840257                                     
--> Q_target: 0.3685590                                     
--> Q_predict: 0.0845333                                     
===========
Update to Terminal
--> Episode: 5                                                        
--> Step: 10                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.4685590                                                        
--> Target-Predict: 0.5904900                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.4095100                                                         
===========
Update to -O----T
--> Episode: 6                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000811                                    
--> MAX Q[S_next,A] = 0.0004413                                    
--> Reward: 0                                     
--> Target-Predict: 0.0003512                                     
--> Q_target: 0.0003971                                     
--> Q_predict: 0.0000459                                     
===========
Update to --O---T
--> Episode: 6                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0006962                                    
--> MAX Q[S_next,A] = 0.0033227                                    
--> Reward: 0                                     
--> Target-Predict: 0.0025492                                     
--> Q_target: 0.0029904                                     
--> Q_predict: 0.0004413                                     
===========
Update to ---O--T
--> Episode: 6                                    
--> Step: 3                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0047169                                    
--> MAX Q[S_next,A] = 0.0191834                                    
--> Reward: 0                                     
--> Target-Predict: 0.0139423                                     
--> Q_target: 0.0172650                                     
--> Q_predict: 0.0033227                                     
===========
Update to ----O-T
--> Episode: 6                                    
--> Step: 4                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0274293                                    
--> MAX Q[S_next,A] = 0.1129359                                    
--> Reward: 0                                     
--> Target-Predict: 0.0824589                                     
--> Q_target: 0.1016423                                     
--> Q_predict: 0.0191834                                     
===========
Update to -----OT
--> Episode: 6                                    
--> Step: 5                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.1438126                                    
--> MAX Q[S_next,A] = 0.4685590                                    
--> Reward: 0                                     
--> Target-Predict: 0.3087672                                     
--> Q_target: 0.4217031                                     
--> Q_predict: 0.1129359                                     
===========
Update to Terminal
--> Episode: 6                                                        
--> Step: 6                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.5217031                                                        
--> Target-Predict: 0.5314410                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.4685590                                                         
===========
Update to ----O-T
--> Episode: 7                                    
--> Step: 1                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0376295                                    
--> MAX Q[S_next,A] = 0.1438126                                    
--> Reward: 0                                     
--> Target-Predict: 0.1020021                                     
--> Q_target: 0.1294313                                     
--> Q_predict: 0.0274293                                     
===========
Update to -----OT
--> Episode: 7                                    
--> Step: 2                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.1763846                                    
--> MAX Q[S_next,A] = 0.5217031                                    
--> Reward: 0                                     
--> Target-Predict: 0.3257202                                     
--> Q_target: 0.4695328                                     
--> Q_predict: 0.1438126                                     
===========
Update to Terminal
--> Episode: 7                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.5695328                                                        
--> Target-Predict: 0.4782969                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.5217031                                                         
===========
Update to -O----T
--> Episode: 8                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0001356                                    
--> MAX Q[S_next,A] = 0.0006962                                    
--> Reward: 0                                     
--> Target-Predict: 0.0005455                                     
--> Q_target: 0.0006266                                     
--> Q_predict: 0.0000811                                     
===========
Update to --O---T
--> Episode: 8                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0010511                                    
--> MAX Q[S_next,A] = 0.0047169                                    
--> Reward: 0                                     
--> Target-Predict: 0.0035491                                     
--> Q_target: 0.0042452                                     
--> Q_predict: 0.0006962                                     
===========
Update to ---O--T
--> Episode: 8                                    
--> Step: 3                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0076319                                    
--> MAX Q[S_next,A] = 0.0376295                                    
--> Reward: 0                                     
--> Target-Predict: 0.0291496                                     
--> Q_target: 0.0338665                                     
--> Q_predict: 0.0047169                                     
===========
Update to ----O-T
--> Episode: 8                                    
--> Step: 4                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0497411                                    
--> MAX Q[S_next,A] = 0.1763846                                    
--> Reward: 0                                     
--> Target-Predict: 0.1211167                                     
--> Q_target: 0.1587462                                     
--> Q_predict: 0.0376295                                     
===========
Update to -----OT
--> Episode: 8                                    
--> Step: 5                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.2100041                                    
--> MAX Q[S_next,A] = 0.5695328                                    
--> Reward: 0                                     
--> Target-Predict: 0.3361949                                     
--> Q_target: 0.5125795                                     
--> Q_predict: 0.1763846                                     
===========
Update to Terminal
--> Episode: 8                                                        
--> Step: 6                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.6125795                                                        
--> Target-Predict: 0.4304672                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.5695328                                                         
===========
Update to --O---T
--> Episode: 9                                    
--> Step: 1                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0016328                                    
--> MAX Q[S_next,A] = 0.0076319                                    
--> Reward: 0                                     
--> Target-Predict: 0.0058176                                     
--> Q_target: 0.0068687                                     
--> Q_predict: 0.0010511                                     
===========
Update to ---O--T
--> Episode: 9                                    
--> Step: 2                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0113454                                    
--> MAX Q[S_next,A] = 0.0497411                                    
--> Reward: 0                                     
--> Target-Predict: 0.0371351                                     
--> Q_target: 0.0447670                                     
--> Q_predict: 0.0076319                                     
===========
Update to ----O-T
--> Episode: 9                                    
--> Step: 3                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0636674                                    
--> MAX Q[S_next,A] = 0.2100041                                    
--> Reward: 0                                     
--> Target-Predict: 0.1392626                                     
--> Q_target: 0.1890037                                     
--> Q_predict: 0.0497411                                     
===========
Update to -----OT
--> Episode: 9                                    
--> Step: 4                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.2441359                                    
--> MAX Q[S_next,A] = 0.6125795                                    
--> Reward: 0                                     
--> Target-Predict: 0.3413175                                     
--> Q_target: 0.5513216                                     
--> Q_predict: 0.2100041                                     
===========
Update to Terminal
--> Episode: 9                                                        
--> Step: 5                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.6513216                                                        
--> Target-Predict: 0.3874205                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6125795                                                         
===========
Update to ---O--T
--> Episode: 10                                    
--> Step: 1                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0159409                                    
--> MAX Q[S_next,A] = 0.0636674                                    
--> Reward: 0                                     
--> Target-Predict: 0.0459553                                     
--> Q_target: 0.0573007                                     
--> Q_predict: 0.0113454                                     
===========
Update to ----O-T
--> Episode: 10                                    
--> Step: 2                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0792729                                    
--> MAX Q[S_next,A] = 0.2441359                                    
--> Reward: 0                                     
--> Target-Predict: 0.1560549                                     
--> Q_target: 0.2197223                                     
--> Q_predict: 0.0636674                                     
===========
Update to -----OT
--> Episode: 10                                    
--> Step: 3                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.2783412                                    
--> MAX Q[S_next,A] = 0.6513216                                    
--> Reward: 0                                     
--> Target-Predict: 0.3420535                                     
--> Q_target: 0.5861894                                     
--> Q_predict: 0.2441359                                     
===========
Update to Terminal
--> Episode: 10                                                        
--> Step: 4                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.6861894                                                        
--> Target-Predict: 0.3486784                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6513216                                                         
===========
Update to ----O-T
--> Episode: 11                                    
--> Step: 1                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.0963963                                    
--> MAX Q[S_next,A] = 0.2783412                                    
--> Reward: 0                                     
--> Target-Predict: 0.1712342                                     
--> Q_target: 0.2505071                                     
--> Q_predict: 0.0792729                                     
===========
Update to -----OT
--> Episode: 11                                    
--> Step: 2                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.3122641                                    
--> MAX Q[S_next,A] = 0.6861894                                    
--> Reward: 0                                     
--> Target-Predict: 0.3392293                                     
--> Q_target: 0.6175705                                     
--> Q_predict: 0.2783412                                     
===========
Update to O-----T
--> Episode: 11                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[5,left] = 0.0000126                                    
--> MAX Q[S_next,A] = 0.0001356                                    
--> Reward: 0                                     
--> Target-Predict: 0.0001217                                     
--> Q_target: 0.0001220                                     
--> Q_predict: 0.0000004                                     
===========
Update to -O----T
--> Episode: 11                                    
--> Step: 4                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0002690                                    
--> MAX Q[S_next,A] = 0.0016328                                    
--> Reward: 0                                     
--> Target-Predict: 0.0013340                                     
--> Q_target: 0.0014696                                     
--> Q_predict: 0.0001356                                     
===========
Update to --O---T
--> Episode: 11                                    
--> Step: 5                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0029042                                    
--> MAX Q[S_next,A] = 0.0159409                                    
--> Reward: 0                                     
--> Target-Predict: 0.0127140                                     
--> Q_target: 0.0143468                                     
--> Q_predict: 0.0016328                                     
===========
Update to ---O--T
--> Episode: 11                                    
--> Step: 6                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0230225                                    
--> MAX Q[S_next,A] = 0.0963963                                    
--> Reward: 0                                     
--> Target-Predict: 0.0708157                                     
--> Q_target: 0.0867567                                     
--> Q_predict: 0.0159409                                     
===========
Update to O-----T
--> Episode: 11                                    
--> Step: 7                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[3,left] = 0.0000263                                    
--> MAX Q[S_next,A] = 0.0002690                                    
--> Reward: 0                                     
--> Target-Predict: 0.0002398                                     
--> Q_target: 0.0002421                                     
--> Q_predict: 0.0000023                                     
===========
Update to -O----T
--> Episode: 11                                    
--> Step: 8                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0005035                                    
--> MAX Q[S_next,A] = 0.0029042                                    
--> Reward: 0                                     
--> Target-Predict: 0.0023448                                     
--> Q_target: 0.0026138                                     
--> Q_predict: 0.0002690                                     
===========
Update to --O---T
--> Episode: 11                                    
--> Step: 9                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0046858                                    
--> MAX Q[S_next,A] = 0.0230225                                    
--> Reward: 0                                     
--> Target-Predict: 0.0178160                                     
--> Q_target: 0.0207203                                     
--> Q_predict: 0.0029042                                     
===========
Update to ---O--T
--> Episode: 11                                    
--> Step: 10                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0293959                                    
--> MAX Q[S_next,A] = 0.0963963                                    
--> Reward: 0                                     
--> Target-Predict: 0.0637342                                     
--> Q_target: 0.0867567                                     
--> Q_predict: 0.0230225                                     
===========
Update to ----O-T
--> Episode: 11                                    
--> Step: 11                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.1148604                                    
--> MAX Q[S_next,A] = 0.3122641                                    
--> Reward: 0                                     
--> Target-Predict: 0.1846414                                     
--> Q_target: 0.2810377                                     
--> Q_predict: 0.0963963                                     
===========
Update to O-----T
--> Episode: 11                                    
--> Step: 12                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[4,left] = 0.0000454                                    
--> MAX Q[S_next,A] = 0.0005035                                    
--> Reward: 0                                     
--> Target-Predict: 0.0004530                                     
--> Q_target: 0.0004531                                     
--> Q_predict: 0.0000001                                     
===========
Update to -O----T
--> Episode: 11                                    
--> Step: 13                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0008749                                    
--> MAX Q[S_next,A] = 0.0046858                                    
--> Reward: 0                                     
--> Target-Predict: 0.0037138                                     
--> Q_target: 0.0042173                                     
--> Q_predict: 0.0005035                                     
===========
Update to --O---T
--> Episode: 11                                    
--> Step: 14                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0068629                                    
--> MAX Q[S_next,A] = 0.0293959                                    
--> Reward: 0                                     
--> Target-Predict: 0.0217705                                     
--> Q_target: 0.0264563                                     
--> Q_predict: 0.0046858                                     
===========
Update to ---O--T
--> Episode: 11                                    
--> Step: 15                                     
--> Next State: 3                                     
--> Chosen Action by current state: right                                     
--> New Q[2,right] = 0.0367938                                    
--> MAX Q[S_next,A] = 0.1148604                                    
--> Reward: 0                                     
--> Target-Predict: 0.0739785                                     
--> Q_target: 0.1033744                                     
--> Q_predict: 0.0293959                                     
===========
Update to ----O-T
--> Episode: 11                                    
--> Step: 16                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.1314782                                    
--> MAX Q[S_next,A] = 0.3122641                                    
--> Reward: 0                                     
--> Target-Predict: 0.1661773                                     
--> Q_target: 0.2810377                                     
--> Q_predict: 0.1148604                                     
===========
Update to -----OT
--> Episode: 11                                    
--> Step: 17                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.3427948                                    
--> MAX Q[S_next,A] = 0.6861894                                    
--> Reward: 0                                     
--> Target-Predict: 0.3053063                                     
--> Q_target: 0.6175705                                     
--> Q_predict: 0.3122641                                     
===========
Update to Terminal
--> Episode: 11                                                        
--> Step: 18                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.7175705                                                        
--> Target-Predict: 0.3138106                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6861894                                                         
===========
Update to ----O-T
--> Episode: 12                                    
--> Step: 1                                     
--> Next State: 4                                     
--> Chosen Action by current state: right                                     
--> New Q[3,right] = 0.1491819                                    
--> MAX Q[S_next,A] = 0.3427948                                    
--> Reward: 0                                     
--> Target-Predict: 0.1770371                                     
--> Q_target: 0.3085153                                     
--> Q_predict: 0.1314782                                     
===========
Update to -----OT
--> Episode: 12                                    
--> Step: 2                                     
--> Next State: 5                                     
--> Chosen Action by current state: right                                     
--> New Q[4,right] = 0.3730966                                    
--> MAX Q[S_next,A] = 0.7175705                                    
--> Reward: 0                                     
--> Target-Predict: 0.3030186                                     
--> Q_target: 0.6458134                                     
--> Q_predict: 0.3427948                                     
===========
Update to Terminal
--> Episode: 12                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[5,right] = 0.7458134                                                        
--> Target-Predict: 0.2824295                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.7175705                                                         
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to Terminal
--> Episode: 0                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.1000000                                                        
--> Target-Predict: 1.0000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.0000000                                                         
===========
Update to O--T
--> Episode: 1                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 2                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 3                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 4                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 5                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 6                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 7                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 8                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 9                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 10                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 11                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 12                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 13                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 1                                    
--> Step: 14                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0090000                                    
--> MAX Q[S_next,A] = 0.1000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0900000                                     
--> Q_target: 0.0900000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 15                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 16                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0008100                                    
--> MAX Q[S_next,A] = 0.0090000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0081000                                     
--> Q_target: 0.0081000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 17                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000729                                    
--> MAX Q[S_next,A] = 0.0008100                                    
--> Reward: 0                                     
--> Target-Predict: 0.0007290                                     
--> Q_target: 0.0007290                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 18                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000729                                    
--> MAX Q[S_next,A] = 0.0008100                                    
--> Reward: 0                                     
--> Target-Predict: 0.0007290                                     
--> Q_target: 0.0007290                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 19                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0015390                                    
--> MAX Q[S_next,A] = 0.0090000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0072900                                     
--> Q_target: 0.0081000                                     
--> Q_predict: 0.0008100                                     
===========
Update to --OT
--> Episode: 1                                    
--> Step: 20                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0171000                                    
--> MAX Q[S_next,A] = 0.1000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0810000                                     
--> Q_target: 0.0900000                                     
--> Q_predict: 0.0090000                                     
===========
Update to Terminal
--> Episode: 1                                                        
--> Step: 21                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.1900000                                                        
--> Target-Predict: 0.9000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.1000000                                                         
===========
Update to -O-T
--> Episode: 2                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0029241                                    
--> MAX Q[S_next,A] = 0.0171000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0138510                                     
--> Q_target: 0.0153900                                     
--> Q_predict: 0.0015390                                     
===========
Update to O--T
--> Episode: 2                                    
--> Step: 2                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0003288                                    
--> MAX Q[S_next,A] = 0.0029241                                    
--> Reward: 0                                     
--> Target-Predict: 0.0025588                                     
--> Q_target: 0.0026317                                     
--> Q_predict: 0.0000729                                     
===========
Update to -O-T
--> Episode: 2                                    
--> Step: 3                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0041707                                    
--> MAX Q[S_next,A] = 0.0171000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0124659                                     
--> Q_target: 0.0153900                                     
--> Q_predict: 0.0029241                                     
===========
Update to --OT
--> Episode: 2                                    
--> Step: 4                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0324900                                    
--> MAX Q[S_next,A] = 0.1900000                                    
--> Reward: 0                                     
--> Target-Predict: 0.1539000                                     
--> Q_target: 0.1710000                                     
--> Q_predict: 0.0171000                                     
===========
Update to Terminal
--> Episode: 2                                                        
--> Step: 5                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.2710000                                                        
--> Target-Predict: 0.8100000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.1900000                                                         
===========
Update to -O-T
--> Episode: 3                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0066777                                    
--> MAX Q[S_next,A] = 0.0324900                                    
--> Reward: 0                                     
--> Target-Predict: 0.0250703                                     
--> Q_target: 0.0292410                                     
--> Q_predict: 0.0041707                                     
===========
Update to --OT
--> Episode: 3                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0536310                                    
--> MAX Q[S_next,A] = 0.2710000                                    
--> Reward: 0                                     
--> Target-Predict: 0.2114100                                     
--> Q_target: 0.2439000                                     
--> Q_predict: 0.0324900                                     
===========
Update to O--T
--> Episode: 3                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0006010                                    
--> MAX Q[S_next,A] = 0.0066777                                    
--> Reward: 0                                     
--> Target-Predict: 0.0060099                                     
--> Q_target: 0.0060099                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 3                                    
--> Step: 4                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0108367                                    
--> MAX Q[S_next,A] = 0.0536310                                    
--> Reward: 0                                     
--> Target-Predict: 0.0415902                                     
--> Q_target: 0.0482679                                     
--> Q_predict: 0.0066777                                     
===========
Update to --OT
--> Episode: 3                                    
--> Step: 5                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0726579                                    
--> MAX Q[S_next,A] = 0.2710000                                    
--> Reward: 0                                     
--> Target-Predict: 0.1902690                                     
--> Q_target: 0.2439000                                     
--> Q_predict: 0.0536310                                     
===========
Update to Terminal
--> Episode: 3                                                        
--> Step: 6                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.3439000                                                        
--> Target-Predict: 0.7290000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.2710000                                                         
===========
Update to -O-T
--> Episode: 4                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0162923                                    
--> MAX Q[S_next,A] = 0.0726579                                    
--> Reward: 0                                     
--> Target-Predict: 0.0545554                                     
--> Q_target: 0.0653921                                     
--> Q_predict: 0.0108367                                     
===========
Update to --OT
--> Episode: 4                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0963431                                    
--> MAX Q[S_next,A] = 0.3439000                                    
--> Reward: 0                                     
--> Target-Predict: 0.2368521                                     
--> Q_target: 0.3095100                                     
--> Q_predict: 0.0726579                                     
===========
Update to Terminal
--> Episode: 4                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.4095100                                                        
--> Target-Predict: 0.6561000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.3439000                                                         
===========
Update to -O-T
--> Episode: 5                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0233339                                    
--> MAX Q[S_next,A] = 0.0963431                                    
--> Reward: 0                                     
--> Target-Predict: 0.0704165                                     
--> Q_target: 0.0867088                                     
--> Q_predict: 0.0162923                                     
===========
Update to --OT
--> Episode: 5                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.1235647                                    
--> MAX Q[S_next,A] = 0.4095100                                    
--> Reward: 0                                     
--> Target-Predict: 0.2722159                                     
--> Q_target: 0.3685590                                     
--> Q_predict: 0.0963431                                     
===========
Update to Terminal
--> Episode: 5                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.4685590                                                        
--> Target-Predict: 0.5904900                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.4095100                                                         
===========
Update to -O-T
--> Episode: 6                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0321214                                    
--> MAX Q[S_next,A] = 0.1235647                                    
--> Reward: 0                                     
--> Target-Predict: 0.0878743                                     
--> Q_target: 0.1112082                                     
--> Q_predict: 0.0233339                                     
===========
Update to --OT
--> Episode: 6                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.1533785                                    
--> MAX Q[S_next,A] = 0.4685590                                    
--> Reward: 0                                     
--> Target-Predict: 0.2981384                                     
--> Q_target: 0.4217031                                     
--> Q_predict: 0.1235647                                     
===========
Update to Terminal
--> Episode: 6                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.5217031                                                        
--> Target-Predict: 0.5314410                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.4685590                                                         
===========
Update to -O-T
--> Episode: 7                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0427133                                    
--> MAX Q[S_next,A] = 0.1533785                                    
--> Reward: 0                                     
--> Target-Predict: 0.1059193                                     
--> Q_target: 0.1380407                                     
--> Q_predict: 0.0321214                                     
===========
Update to --OT
--> Episode: 7                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.1849940                                    
--> MAX Q[S_next,A] = 0.5217031                                    
--> Reward: 0                                     
--> Target-Predict: 0.3161543                                     
--> Q_target: 0.4695328                                     
--> Q_predict: 0.1533785                                     
===========
Update to Terminal
--> Episode: 7                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.5695328                                                        
--> Target-Predict: 0.4782969                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.5217031                                                         
===========
Update to -O-T
--> Episode: 8                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0550914                                    
--> MAX Q[S_next,A] = 0.1849940                                    
--> Reward: 0                                     
--> Target-Predict: 0.1237813                                     
--> Q_target: 0.1664946                                     
--> Q_predict: 0.0427133                                     
===========
Update to --OT
--> Episode: 8                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.2177525                                    
--> MAX Q[S_next,A] = 0.5695328                                    
--> Reward: 0                                     
--> Target-Predict: 0.3275855                                     
--> Q_target: 0.5125795                                     
--> Q_predict: 0.1849940                                     
===========
Update to Terminal
--> Episode: 8                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.6125795                                                        
--> Target-Predict: 0.4304672                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.5695328                                                         
===========
Update to -O-T
--> Episode: 9                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0691800                                    
--> MAX Q[S_next,A] = 0.2177525                                    
--> Reward: 0                                     
--> Target-Predict: 0.1408858                                     
--> Q_target: 0.1959773                                     
--> Q_predict: 0.0550914                                     
===========
Update to --OT
--> Episode: 9                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.2511094                                    
--> MAX Q[S_next,A] = 0.6125795                                    
--> Reward: 0                                     
--> Target-Predict: 0.3335690                                     
--> Q_target: 0.5513216                                     
--> Q_predict: 0.2177525                                     
===========
Update to Terminal
--> Episode: 9                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.6513216                                                        
--> Target-Predict: 0.3874205                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6125795                                                         
===========
Update to -O-T
--> Episode: 10                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0848619                                    
--> MAX Q[S_next,A] = 0.2511094                                    
--> Reward: 0                                     
--> Target-Predict: 0.1568185                                     
--> Q_target: 0.2259985                                     
--> Q_predict: 0.0691800                                     
===========
Update to --OT
--> Episode: 10                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.2846174                                    
--> MAX Q[S_next,A] = 0.6513216                                    
--> Reward: 0                                     
--> Target-Predict: 0.3350800                                     
--> Q_target: 0.5861894                                     
--> Q_predict: 0.2511094                                     
===========
Update to Terminal
--> Episode: 10                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.6861894                                                        
--> Target-Predict: 0.3486784                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6513216                                                         
===========
Update to -O-T
--> Episode: 11                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.1019912                                    
--> MAX Q[S_next,A] = 0.2846174                                    
--> Reward: 0                                     
--> Target-Predict: 0.1712938                                     
--> Q_target: 0.2561557                                     
--> Q_predict: 0.0848619                                     
===========
Update to --OT
--> Episode: 11                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.3179127                                    
--> MAX Q[S_next,A] = 0.6861894                                    
--> Reward: 0                                     
--> Target-Predict: 0.3329530                                     
--> Q_target: 0.6175705                                     
--> Q_predict: 0.2846174                                     
===========
Update to Terminal
--> Episode: 11                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.7175705                                                        
--> Target-Predict: 0.3138106                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6861894                                                         
===========
Update to -O-T
--> Episode: 12                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.1204043                                    
--> MAX Q[S_next,A] = 0.3179127                                    
--> Reward: 0                                     
--> Target-Predict: 0.1841302                                     
--> Q_target: 0.2861215                                     
--> Q_predict: 0.1019912                                     
===========
Update to --OT
--> Episode: 12                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.3507028                                    
--> MAX Q[S_next,A] = 0.7175705                                    
--> Reward: 0                                     
--> Target-Predict: 0.3279007                                     
--> Q_target: 0.6458134                                     
--> Q_predict: 0.3179127                                     
===========
Update to Terminal
--> Episode: 12                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.7458134                                                        
--> Target-Predict: 0.2824295                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.7175705                                                         
===========
Update to O--T
--> Episode: 0                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 2                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 4                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 5                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 6                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 7                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 8                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 9                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 10                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 11                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 12                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 13                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 14                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 15                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 16                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 17                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 18                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 19                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 20                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 21                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 22                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 23                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 24                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 25                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 26                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 27                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 28                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 29                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 30                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to Terminal
--> Episode: 0                                                        
--> Step: 31                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.1000000                                                        
--> Target-Predict: 1.0000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.0000000                                                         
===========
Update to O--T
--> Episode: 1                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 2                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 4                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 1                                    
--> Step: 5                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0090000                                    
--> MAX Q[S_next,A] = 0.1000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0900000                                     
--> Q_target: 0.0900000                                     
--> Q_predict: 0.0000000                                     
===========
Update to Terminal
--> Episode: 1                                                        
--> Step: 6                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.1900000                                                        
--> Target-Predict: 0.9000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.1000000                                                         
===========
Update to O--T
--> Episode: 2                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 2                                    
--> Step: 2                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0008100                                    
--> MAX Q[S_next,A] = 0.0090000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0081000                                     
--> Q_target: 0.0081000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 2                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000729                                    
--> MAX Q[S_next,A] = 0.0008100                                    
--> Reward: 0                                     
--> Target-Predict: 0.0007290                                     
--> Q_target: 0.0007290                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 2                                    
--> Step: 4                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0015390                                    
--> MAX Q[S_next,A] = 0.0090000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0072900                                     
--> Q_target: 0.0081000                                     
--> Q_predict: 0.0008100                                     
===========
Update to --OT
--> Episode: 2                                    
--> Step: 5                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0252000                                    
--> MAX Q[S_next,A] = 0.1900000                                    
--> Reward: 0                                     
--> Target-Predict: 0.1620000                                     
--> Q_target: 0.1710000                                     
--> Q_predict: 0.0090000                                     
===========
Update to O--T
--> Episode: 2                                    
--> Step: 6                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0001385                                    
--> MAX Q[S_next,A] = 0.0015390                                    
--> Reward: 0                                     
--> Target-Predict: 0.0013851                                     
--> Q_target: 0.0013851                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 2                                    
--> Step: 7                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0001385                                    
--> MAX Q[S_next,A] = 0.0015390                                    
--> Reward: 0                                     
--> Target-Predict: 0.0013851                                     
--> Q_target: 0.0013851                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 2                                    
--> Step: 8                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0036531                                    
--> MAX Q[S_next,A] = 0.0252000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0211410                                     
--> Q_target: 0.0226800                                     
--> Q_predict: 0.0015390                                     
===========
Update to --OT
--> Episode: 2                                    
--> Step: 9                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0397800                                    
--> MAX Q[S_next,A] = 0.1900000                                    
--> Reward: 0                                     
--> Target-Predict: 0.1458000                                     
--> Q_target: 0.1710000                                     
--> Q_predict: 0.0252000                                     
===========
Update to Terminal
--> Episode: 2                                                        
--> Step: 10                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.2710000                                                        
--> Target-Predict: 0.8100000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.1900000                                                         
===========
Update to O--T
--> Episode: 3                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0004534                                    
--> MAX Q[S_next,A] = 0.0036531                                    
--> Reward: 0                                     
--> Target-Predict: 0.0031493                                     
--> Q_target: 0.0032878                                     
--> Q_predict: 0.0001385                                     
===========
Update to -O-T
--> Episode: 3                                    
--> Step: 2                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0068680                                    
--> MAX Q[S_next,A] = 0.0397800                                    
--> Reward: 0                                     
--> Target-Predict: 0.0321489                                     
--> Q_target: 0.0358020                                     
--> Q_predict: 0.0036531                                     
===========
Update to O--T
--> Episode: 3                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0006837                                    
--> MAX Q[S_next,A] = 0.0068680                                    
--> Reward: 0                                     
--> Target-Predict: 0.0061083                                     
--> Q_target: 0.0061812                                     
--> Q_predict: 0.0000729                                     
===========
Update to -O-T
--> Episode: 3                                    
--> Step: 4                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0097614                                    
--> MAX Q[S_next,A] = 0.0397800                                    
--> Reward: 0                                     
--> Target-Predict: 0.0289340                                     
--> Q_target: 0.0358020                                     
--> Q_predict: 0.0068680                                     
===========
Update to --OT
--> Episode: 3                                    
--> Step: 5                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0601920                                    
--> MAX Q[S_next,A] = 0.2710000                                    
--> Reward: 0                                     
--> Target-Predict: 0.2041200                                     
--> Q_target: 0.2439000                                     
--> Q_predict: 0.0397800                                     
===========
Update to Terminal
--> Episode: 3                                                        
--> Step: 6                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.3439000                                                        
--> Target-Predict: 0.7290000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.2710000                                                         
===========
Update to -O-T
--> Episode: 4                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0142025                                    
--> MAX Q[S_next,A] = 0.0601920                                    
--> Reward: 0                                     
--> Target-Predict: 0.0444114                                     
--> Q_target: 0.0541728                                     
--> Q_predict: 0.0097614                                     
===========
Update to --OT
--> Episode: 4                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0851238                                    
--> MAX Q[S_next,A] = 0.3439000                                    
--> Reward: 0                                     
--> Target-Predict: 0.2493180                                     
--> Q_target: 0.3095100                                     
--> Q_predict: 0.0601920                                     
===========
Update to Terminal
--> Episode: 4                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.4095100                                                        
--> Target-Predict: 0.6561000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.3439000                                                         
===========
Update to -O-T
--> Episode: 5                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0204434                                    
--> MAX Q[S_next,A] = 0.0851238                                    
--> Reward: 0                                     
--> Target-Predict: 0.0624089                                     
--> Q_target: 0.0766114                                     
--> Q_predict: 0.0142025                                     
===========
Update to --OT
--> Episode: 5                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.1134673                                    
--> MAX Q[S_next,A] = 0.4095100                                    
--> Reward: 0                                     
--> Target-Predict: 0.2834352                                     
--> Q_target: 0.3685590                                     
--> Q_predict: 0.0851238                                     
===========
Update to Terminal
--> Episode: 5                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.4685590                                                        
--> Target-Predict: 0.5904900                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.4095100                                                         
===========
Update to -O-T
--> Episode: 6                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0286111                                    
--> MAX Q[S_next,A] = 0.1134673                                    
--> Reward: 0                                     
--> Target-Predict: 0.0816772                                     
--> Q_target: 0.1021206                                     
--> Q_predict: 0.0204434                                     
===========
Update to --OT
--> Episode: 6                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.1442909                                    
--> MAX Q[S_next,A] = 0.4685590                                    
--> Reward: 0                                     
--> Target-Predict: 0.3082358                                     
--> Q_target: 0.4217031                                     
--> Q_predict: 0.1134673                                     
===========
Update to Terminal
--> Episode: 6                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.5217031                                                        
--> Target-Predict: 0.5314410                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.4685590                                                         
===========
Update to -O-T
--> Episode: 7                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0387362                                    
--> MAX Q[S_next,A] = 0.1442909                                    
--> Reward: 0                                     
--> Target-Predict: 0.1012507                                     
--> Q_target: 0.1298618                                     
--> Q_predict: 0.0286111                                     
===========
Update to --OT
--> Episode: 7                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.1768151                                    
--> MAX Q[S_next,A] = 0.5217031                                    
--> Reward: 0                                     
--> Target-Predict: 0.3252419                                     
--> Q_target: 0.4695328                                     
--> Q_predict: 0.1442909                                     
===========
Update to Terminal
--> Episode: 7                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.5695328                                                        
--> Target-Predict: 0.4782969                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.5217031                                                         
===========
Update to -O-T
--> Episode: 8                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0507759                                    
--> MAX Q[S_next,A] = 0.1768151                                    
--> Reward: 0                                     
--> Target-Predict: 0.1203974                                     
--> Q_target: 0.1591336                                     
--> Q_predict: 0.0387362                                     
===========
Update to --OT
--> Episode: 8                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.2103915                                    
--> MAX Q[S_next,A] = 0.5695328                                    
--> Reward: 0                                     
--> Target-Predict: 0.3357644                                     
--> Q_target: 0.5125795                                     
--> Q_predict: 0.1768151                                     
===========
Update to Terminal
--> Episode: 8                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.6125795                                                        
--> Target-Predict: 0.4304672                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.5695328                                                         
===========
Update to -O-T
--> Episode: 9                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0646336                                    
--> MAX Q[S_next,A] = 0.2103915                                    
--> Reward: 0                                     
--> Target-Predict: 0.1385764                                     
--> Q_target: 0.1893524                                     
--> Q_predict: 0.0507759                                     
===========
Update to --OT
--> Episode: 9                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.2444845                                    
--> MAX Q[S_next,A] = 0.6125795                                    
--> Reward: 0                                     
--> Target-Predict: 0.3409300                                     
--> Q_target: 0.5513216                                     
--> Q_predict: 0.2103915                                     
===========
Update to Terminal
--> Episode: 9                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.6513216                                                        
--> Target-Predict: 0.3874205                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6125795                                                         
===========
Update to -O-T
--> Episode: 10                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0801738                                    
--> MAX Q[S_next,A] = 0.2444845                                    
--> Reward: 0                                     
--> Target-Predict: 0.1554025                                     
--> Q_target: 0.2200361                                     
--> Q_predict: 0.0646336                                     
===========
Update to --OT
--> Episode: 10                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.2786550                                    
--> MAX Q[S_next,A] = 0.6513216                                    
--> Reward: 0                                     
--> Target-Predict: 0.3417049                                     
--> Q_target: 0.5861894                                     
--> Q_predict: 0.2444845                                     
===========
Update to Terminal
--> Episode: 10                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.6861894                                                        
--> Target-Predict: 0.3486784                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6513216                                                         
===========
Update to -O-T
--> Episode: 11                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0972354                                    
--> MAX Q[S_next,A] = 0.2786550                                    
--> Reward: 0                                     
--> Target-Predict: 0.1706157                                     
--> Q_target: 0.2507895                                     
--> Q_predict: 0.0801738                                     
===========
Update to --OT
--> Episode: 11                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.3125466                                    
--> MAX Q[S_next,A] = 0.6861894                                    
--> Reward: 0                                     
--> Target-Predict: 0.3389154                                     
--> Q_target: 0.6175705                                     
--> Q_predict: 0.2786550                                     
===========
Update to Terminal
--> Episode: 11                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.7175705                                                        
--> Target-Predict: 0.3138106                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.6861894                                                         
===========
Update to -O-T
--> Episode: 12                                    
--> Step: 1                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.1156411                                    
--> MAX Q[S_next,A] = 0.3125466                                    
--> Reward: 0                                     
--> Target-Predict: 0.1840565                                     
--> Q_target: 0.2812919                                     
--> Q_predict: 0.0972354                                     
===========
Update to --OT
--> Episode: 12                                    
--> Step: 2                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.3458732                                    
--> MAX Q[S_next,A] = 0.7175705                                    
--> Reward: 0                                     
--> Target-Predict: 0.3332669                                     
--> Q_target: 0.6458134                                     
--> Q_predict: 0.3125466                                     
===========
Update to Terminal
--> Episode: 12                                                        
--> Step: 3                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.7458134                                                        
--> Target-Predict: 0.2824295                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.7175705                                                         
===========
Update to O--T
--> Episode: 0                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 2                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 4                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 5                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 6                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 7                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 8                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 9                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 10                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 11                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 12                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 13                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 14                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 15                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 16                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 17                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 18                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 19                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 20                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 21                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 22                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 23                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 24                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 25                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 26                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 27                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 28                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 2                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 4                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 5                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 6                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 7                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 8                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 9                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 10                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 11                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 12                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 13                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to Terminal
--> Episode: 0                                                        
--> Step: 14                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.1000000                                                        
--> Target-Predict: 1.0000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.0000000                                                         
===========
Update to O--T
--> Episode: 1                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 2                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 4                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 5                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 6                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 7                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 8                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 9                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 10                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 11                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 12                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 13                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 14                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 15                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 16                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 17                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 18                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 19                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 0                                    
--> Step: 20                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 0                                    
--> Step: 21                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 0                                    
--> Step: 22                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to Terminal
--> Episode: 0                                                        
--> Step: 23                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.1000000                                                        
--> Target-Predict: 1.0000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.0000000                                                         
===========
Update to O--T
--> Episode: 1                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 2                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 4                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 5                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 6                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 7                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 8                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 9                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 1                                    
--> Step: 10                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0090000                                    
--> MAX Q[S_next,A] = 0.1000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0900000                                     
--> Q_target: 0.0900000                                     
--> Q_predict: 0.0000000                                     
===========
Update to O--T
--> Episode: 1                                    
--> Step: 11                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[2,left] = 0.0000000                                    
--> MAX Q[S_next,A] = 0.0000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0000000                                     
--> Q_target: 0.0000000                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 1                                    
--> Step: 12                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0008100                                    
--> MAX Q[S_next,A] = 0.0090000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0081000                                     
--> Q_target: 0.0081000                                     
--> Q_predict: 0.0000000                                     
===========
Update to --OT
--> Episode: 1                                    
--> Step: 13                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0171000                                    
--> MAX Q[S_next,A] = 0.1000000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0810000                                     
--> Q_target: 0.0900000                                     
--> Q_predict: 0.0090000                                     
===========
Update to Terminal
--> Episode: 1                                                        
--> Step: 14                                                         
--> Chosen Action by current state: right                                                         
--> Reward: 1                                                         
--> New Q[2,right] = 0.1900000                                                        
--> Target-Predict: 0.9000000                                                         
--> Q_target: 1.0000000                                                         
--> Q_predict: 0.1000000                                                         
===========
Update to O--T
--> Episode: 2                                    
--> Step: 1                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[0,left] = 0.0000729                                    
--> MAX Q[S_next,A] = 0.0008100                                    
--> Reward: 0                                     
--> Target-Predict: 0.0007290                                     
--> Q_target: 0.0007290                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 2                                    
--> Step: 2                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0022680                                    
--> MAX Q[S_next,A] = 0.0171000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0145800                                     
--> Q_target: 0.0153900                                     
--> Q_predict: 0.0008100                                     
===========
Update to O--T
--> Episode: 2                                    
--> Step: 3                                     
--> Next State: 0                                     
--> Chosen Action by current state: left                                     
--> New Q[1,left] = 0.0002041                                    
--> MAX Q[S_next,A] = 0.0022680                                    
--> Reward: 0                                     
--> Target-Predict: 0.0020412                                     
--> Q_target: 0.0020412                                     
--> Q_predict: 0.0000000                                     
===========
Update to -O-T
--> Episode: 2                                    
--> Step: 4                                     
--> Next State: 1                                     
--> Chosen Action by current state: right                                     
--> New Q[0,right] = 0.0035802                                    
--> MAX Q[S_next,A] = 0.0171000                                    
--> Reward: 0                                     
--> Target-Predict: 0.0131220                                     
--> Q_target: 0.0153900                                     
--> Q_predict: 0.0022680                                     
===========
Update to --OT
--> Episode: 2                                    
--> Step: 5                                     
--> Next State: 2                                     
--> Chosen Action by current state: right                                     
--> New Q[1,right] = 0.0324900                                    
--> MAX Q[S_next,A] = 0.1900000                                    
--> Reward: 0                                     
--> Target-Predict: 0.1539000                                     
--> Q_target: 0.1710000                                     
--> Q_predict: 0.0171000                                     
===========
